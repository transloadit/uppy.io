---
sidebar_position: 4
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import UppyCdnExample from '/src/components/UppyCdnExample';

# AWS S3 Multipart

The `@uppy/aws-s3-multipart` plugin can be used to upload files directly to an S3 bucket (or S3-compatible provider)
using S3’s Multipart upload strategy.

## When should I use it?

:::tip
Not sure which upload strategy is best for you? Read “[Choosing the upload strategy you need](/docs/guides/choosing-upload-strategy)”.
:::

You can use this plugin when you prefer a _client-to-storage_ over a _client-to-server-to-storage_ (such as [Transloadit](/docs/upload-strategies/transloadit) or [Tus](/docs/upload-strategies/tus)) setup.
This may in some cases be preferable, for instance, to reduce costs or the complexity of running a server and load balancer with [Tus](/docs/upload-strategies/tus).

`@uppy/aws-s3-multipart` starts to become valuable for larger files (100&nbsp;MB+) as it uploads a single object as a set of parts.
This has certain benefits, such as improved throughput (uploading parts in parallel) and quick recovery from network issues (only the failed parts need to be retried).
The downside is request overhead, as it needs to do creation, signing, and completion requests besides the upload requests.
For example, if you are uploading files that are only a couple kilobytes with a 100ms roundtrip latency,
you are spending 400ms on overhead and only a few milliseconds on uploading. 

If you are uploading large files (100&nbsp;MB+), we recommend `@uppy/aws-s3-multipart`, otherwise [`@uppy/aws-s3`][].

## Install

<Tabs>
  <TabItem value="npm" label="NPM" default>

  ```shell
  npm install @uppy/aws-s3-multipart
  ```

  </TabItem>

  <TabItem value="yarn" label="Yarn">

  ```shell
  yarn add @uppy/aws-s3-multipart
  ```

  </TabItem>

  <TabItem value="cdn" label="CDN">
    <UppyCdnExample>
      {`
        import { Uppy, AwsS3Multipart } from "{{UPPY_JS_URL}}"
        new Uppy().use(AwsS3Multipart, { /* see options */ })
      `}
    </UppyCdnExample>
  </TabItem>
</Tabs>

## Use

### Use with your own server

The recommended approach is to integrate `@uppy/aws-s3-multipart` with your own server.
You will need to do the following things:

- [Setup up a S3 bucket](#setting-up-your-s3-bucket)
- Create endpoints in your server (can be any route, below is an example)
  - `POST` > `/uppy/s3`: create the multipart upload
  - `GET` > `/uppy/s3/:id`: get the uploaded parts
  - `GET` > `/uppy/s3/:id/:partNumber`: sign the part and return a pre-signed URL
  - `POST` > `/uppy/s3/:id/complete`: complete the multipart upload
  - `DELETE` > `/uppy/s3/:id`: abort the multipart upload
- Setup Uppy

```js {10} showLineNumbers
import Uppy from '@uppy/core'
import Dashboard from '@uppy/dashboard'
import AwsS3Multipart from '@uppy/aws-s3-multipart'

import '@uppy/core/dist/style.min.css'
import '@uppy/dashboard/dist/style.min.css'

const uppy = new Uppy
  .use(Dashboard, { inline: true, target: 'body' })
  // TODO
```

### Use with Companion

[Companion](/docs/companion) has S3 routes built-in for a plug-and-play experience with Uppy.

:::caution
Generally it’s better for access control, observability, and scaling to integrate `@uppy/aws-s3-multipart`
with your own server. You may want to use [Companion](/docs/companion) for creating, signing,
and completing your S3 uploads if you already need Companion for remote files (such as from Google Drive).
Otherwise it’s not worth the hosting effort.
:::

```js {10} showLineNumbers
import Uppy from '@uppy/core'
import Dashboard from '@uppy/dashboard'
import AwsS3Multipart from '@uppy/aws-s3-multipart'

import '@uppy/core/dist/style.min.css'
import '@uppy/dashboard/dist/style.min.css'

const uppy = new Uppy
  .use(Dashboard, { inline: true, target: 'body' })
  .use(AwsS3Multipart, { companionUrl: 'http://companion.uppy.io' })
```

### Setting up your S3 bucket

To use this plugin with S3 we need to setup a bucket with the right permissions and CORS settings.

S3 buckets do not allow public uploads for security reasons.
To allow Uppy and the browser to upload directly to a bucket, its CORS permissions need to be configured.

CORS permissions can be found in the [S3 Management Console](https://console.aws.amazon.com/s3/home).
Click the bucket that will receive the uploads, then go into the `Permissions` tab and select the `CORS configuration` button.
A JSON document will be shown that defines the CORS configuration. (AWS used to use XML but now only allow JSON).
More information about the [S3 CORS format here](https://docs.amazonaws.cn/en_us/AmazonS3/latest/userguide/ManageCorsUsing.html).

The configuration required for Uppy and Companion is this:

```json
[
  {
    "AllowedOrigins": ["https://my-app.com"],
    "AllowedMethods": ["GET", "PUT"],
    "MaxAgeSeconds": 3000,
    "AllowedHeaders": [
      "Authorization",
      "x-amz-date",
      "x-amz-content-sha256",
      "content-type"
    ],
    "ExposeHeaders": ["ETag"]
  },
  {
    "AllowedOrigins": ["*"],
    "AllowedMethods": ["GET"],
    "MaxAgeSeconds": 3000
  }
]
```

A good practice is to use two CORS rules: one for viewing the uploaded files, and one for uploading files.
This is done above where the first object in the array defines the rules for uploading, and the second for viewing.
The example above **makes files publically viewable**. You can change it according to your needs.

If you are using an IAM policy to allow access to the S3 bucket, the policy must have at least the `s3:PutObject` and `s3:PutObjectAcl` permissions scoped to the bucket in question.
In-depth documentation about CORS rules is available on the [AWS documentation site](https://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html).

## API

### Options

#### `limit`

.....TODO

The maximum amount of chunks to upload simultaneously (`number`, default: `5`).

This affects [`prepareUploadParts()`](#prepareUploadParts-file-partData) as well;
after the initial batch of `limit` parts is presigned, a minimum of `limit / 2` rounded up will be presigned at a time.
You should set the limit carefully.
Setting it to a value too high could cause issues where the presigned URLs begin to expire before the chunks they are for start uploading.
Too low and you will end up with a lot of extra round trips to your server (or Companion) than necessary to presign URLs.
If the default chunk size of 5MB is used, a `limit` between 5 and 15 is recommended.

For example, with a 50MB file and a `limit` of 5 we end up with 10 chunks.
5 of these are presigned in one batch, then 3, then 2, for a total of 3 round trips to the server via [`prepareUploadParts()`](#prepareUploadParts-file-partData) and 10 requests sent to AWS via the presigned URLs generated.

#### `companionUrl`

URL to a [Companion](/docs/companion) instance (`string`, default: `null`).

#### `companionHeaders`

Custom headers that should be sent along to [Companion](/docs/companion) on every request (`Object`, default: `{}`).

#### `companionCookiesRule`

This option correlates to the [RequestCredentials value](https://developer.mozilla.org/en-US/docs/Web/API/Request/credentials) (`string`, default: `'same-origin'`).

This tells the plugin whether to send cookies to [Companion](/docs/companion).

#### `retryDelays`

`retryDelays` are the intervals in milliseconds used to retry a failed chunk (`array`, default: `[0, 1000, 3000, 5000]`).

This is also used for [`prepareUploadParts()`](#prepareuploadpartsfile-partdata).
Set to `null` to disable automatic retries, and fail instantly if any chunk fails to upload.

#### `getChunkSize(file)`

A function that returns the minimum chunk size to use when uploading the given file.

The S3 Multipart plugin uploads files in chunks.
Chunks are sent in batches to have presigned URLs generated with [`prepareUploadParts()`](#prepareuploadpartsfile-partdata).
To reduce the amount of requests for large files, you can choose a larger chunk size, at the cost of having to re-upload more data if one chunk fails to upload.

S3 requires a minimum chunk size of 5MB, and supports at most 10,000 chunks per multipart upload.
If `getChunkSize()` returns a size that’s too small, Uppy will increase it to S3’s minimum requirements.

#### `createMultipartUpload(file)`

A function that calls the S3 Multipart API to create a new upload.

`file` is the file object from Uppy’s state. The most relevant keys are `file.name` and `file.type`.

Return a Promise for an object with keys:

*   `uploadId` - The UploadID returned by S3.
*   `key` - The object key for the file. This needs to be returned to allow it to be different from the `file.name`.

The default implementation calls out to Companion’s S3 signing endpoints.

#### `listParts(file, { uploadId, key })`

A function that calls the S3 Multipart API to list the parts of a file that have already been uploaded.

Receives the `file` object from Uppy’s state, and an object with keys:

*   `uploadId` - The UploadID of this Multipart upload.
*   `key` - The object key of this Multipart upload.

Return a Promise for an array of S3 Part objects, as returned by the S3 Multipart API. Each object has keys:

*   `PartNumber` - The index in the file of the uploaded part.
*   `Size` - The size of the part in bytes.
*   `ETag` - The ETag of the part, used to identify it when completing the multipart upload and combining all parts into a single file.

The default implementation calls out to Companion’s S3 signing endpoints.

#### `prepareUploadParts(file, partData)`

A function that generates a batch of signed URLs for the specified part numbers.

Receives the `file` object from Uppy’s state. The `partData` argument is an object with keys:

*   `uploadId` - The UploadID of this Multipart upload.
*   `key` - The object key in the S3 bucket.
*   `parts` - An array of objects with the part number and chunk (`Array<{ number: number, chunk: blob }>`). `number` can’t be zero.

`prepareUploadParts` should return a `Promise` with an `Object` with keys:

*   `presignedUrls` - A JavaScript object with the part numbers as keys and the presigned URL for each part as the value.
*   `headers` - **(Optional)** Custom headers to send along with every request per part (`{ 1: { 'Content-MD5': 'hash' }}`).
    These are (1-based) indexed by part number too so you can for instance send the MD5 hash validation for each part to S3.

An example of what the return value should look like:

```json
{
  "presignedUrls": {
    "1": "https://bucket.region.amazonaws.com/path/to/file.jpg?partNumber=1&...",
    "2": "https://bucket.region.amazonaws.com/path/to/file.jpg?partNumber=2&...",
    "3": "https://bucket.region.amazonaws.com/path/to/file.jpg?partNumber=3&..."
  },
  "headers": { 
    "1": { "Content-MD5": "foo" },
    "2": { "Content-MD5": "bar" },
    "3": { "Content-MD5": "baz" }
  }
}
```

If an error occured, reject the `Promise` with an `Object` with the following keys:

```json
{ "source": { "status": 500 } }
```

`status` is the HTTP code and is required for determining whether to retry the request. `prepareUploadParts` will be retried if the code is `0`, `409`, `423`, or between `500` and `600`.

#### `abortMultipartUpload(file, { uploadId, key })`

A function that calls the S3 Multipart API to abort a Multipart upload, and removes all parts that have been uploaded so far.

Receives the `file` object from Uppy’s state, and an object with keys:

*   `uploadId` - The UploadID of this Multipart upload.
*   `key` - The object key of this Multipart upload.

This is typically called when the user cancels an upload. Cancellation cannot fail in Uppy, so the result of this function is ignored.

The default implementation calls out to Companion’s S3 signing endpoints.

#### `completeMultipartUpload(file, { uploadId, key, parts })`

A function that calls the S3 Multipart API to complete a Multipart upload, combining all parts into a single object in the S3 bucket.

Receives the `file` object from Uppy’s state, and an object with keys:

*   `uploadId` - The UploadID of this Multipart upload.
*   `key` - The object key of this Multipart upload.
*   `parts` - S3-style list of parts, an array of objects with `ETag` and `PartNumber` properties. This can be passed straight to S3’s Multipart API.

Return a Promise for an object with properties:

*   `location` - **(Optional)** A publically accessible URL to the object in the S3 bucket.

The default implementation calls out to Companion’s S3 signing endpoints.

[`@uppy/aws-s3`]: /docs/upload-strategies/aws-s3
